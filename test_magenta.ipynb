{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functools\n",
    "import os\n",
    "\n",
    "# from matplotlib import gridspec\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "print(\"TF Version: \", tf.__version__)\n",
    "print(\"TF-Hub version: \", hub.__version__)\n",
    "print(\"Eager mode enabled: \", tf.executing_eagerly())\n",
    "print(\"GPU available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Utility functions related to showing and saving images\n",
    "\n",
    "def show_img(images, titles=('',), figsize=(20, 8)):\n",
    "  plt.figure(figsize=figsize)\n",
    "  imgs = len(images)\n",
    "  for i, img in enumerate(images):\n",
    "    plt.subplot(1, imgs, i + 1)\n",
    "    if type(img) == tf.python.framework.ops.EagerTensor:\n",
    "      # The output image is by default an EagerTensor instance, hence we will need to squeeze the image dimensions for display\n",
    "      images[i] = np.squeeze(images[i])\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "def save_image(img, filename, savedir):\n",
    "    plt.imsave(os.path.join(savedir, filename), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Utility functions related to loading the magenta model and stylizing image using magenta model\n",
    "\n",
    "def load_magenta_model():\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # Load image stylization module.\n",
    "    hub_handle = os.path.join(cwd, 'models', 'magenta')\n",
    "    hub_module = hub.load(hub_handle)\n",
    "    return hub_module\n",
    "\n",
    "def style_img_magenta(content_image, style_image, hub_module):\n",
    "    # Convert to float32 numpy array, add batch dimension, and normalize to range [0, 1]. Example using numpy:\n",
    "    ctm = content_image.copy()\n",
    "    stm = style_image.copy()\n",
    "    ctm = ctm.astype(np.float32)[np.newaxis, ...] / 255.\n",
    "    stm = stm.astype(np.float32)[np.newaxis, ...] / 255.\n",
    "\n",
    "    # Optionally resize the images. It is recommended that the style image is about\n",
    "    # 256 pixels (this size was used when training the style transfer network).\n",
    "    # The content image can be any size.\n",
    "    stm = tf.image.resize(stm, (256, 256))\n",
    "\n",
    "    # Stylize image\n",
    "    outputs = hub_module(tf.constant(ctm), tf.constant(stm))\n",
    "    stylized_image = outputs[0]\n",
    "    return stylized_image\n",
    "hub_module = load_magenta_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main program here\n",
    "cwd = os.getcwd()\n",
    "img_dir = os.path.join(cwd, 'images')\n",
    "output_dir = os.path.join(cwd, 'output')\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(os.path.join(cwd, output_dir))\n",
    "\n",
    "# Content image to be chosen\n",
    "content_image_path = './klcc.jpg'\n",
    "content_images = os.listdir(os.path.join(img_dir, 'content'))\n",
    "content_images = sorted(content_images)\n",
    "print(f'The content images available by default are: {content_images}\\n')\n",
    "content_img = content_images[0]\n",
    "content_image_path = os.path.join(img_dir, 'content', content_img)\n",
    "content_image = plt.imread(content_image_path)\n",
    "\n",
    "# Choosing style image\n",
    "style_images = os.listdir(os.path.join(img_dir, 'styles'))\n",
    "style_images = sorted(style_images)\n",
    "print(f'The style images available by default are: {style_images}\\n')\n",
    "style_img = style_images[2]\n",
    "\n",
    "style_image_path = os.path.join(img_dir, 'styles', style_img)\n",
    "style_image = plt.imread(style_image_path)\n",
    "\n",
    "\n",
    "stylized_image = style_img_magenta(content_image=content_image, style_image=style_image, hub_module=hub_module)\n",
    "stylized_image = np.squeeze(stylized_image)  # Prepare EagerTensor image for display\n",
    "\n",
    "save_image(stylized_image, 'styled_output.jpg', output_dir)  # Save stylized image\n",
    "show_img([content_image, style_image, stylized_image], titles=['Original Content Image', 'Style Image', 'Stylized Image (Output)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_style_path(style_img):\n",
    "#     return os.path.join(img_dir, 'styles', style_img)\n",
    "\n",
    "def masked_stylize(content_image, mask, segment_styles):\n",
    "    # `styles` parameter MUST BE a list of styles, if no style for the current class index, specify as `None`\n",
    "    styles_to_segment = set(segment_styles.keys())\n",
    "    n_sty = len(styles_to_segment)\n",
    "    \n",
    "    mask_classes = list(np.unique(mask))\n",
    "    n_classes = len(mask_classes)\n",
    "\n",
    "    if ((n_sty > n_classes) or n_sty == 0):\n",
    "        raise Exception('Error: number of styles does not match the number of segmented regions in the mask or no style is passed in')\n",
    "\n",
    "    norm_ctm = content_image.copy().astype(np.float32) / 255.\n",
    "    stylized_image = norm_ctm.copy()\n",
    "    cur_mask = 0  # Temporary variable that stores the mask for the current class involved\n",
    "    cur_layer = 0  # Temporary variable that stores the processed layer for the current class involved\n",
    "\n",
    "    for i, val in enumerate(mask_classes):\n",
    "        # `val` indicates the value of the current class within the image mask\n",
    "        if i not in styles_to_segment:\n",
    "            continue\n",
    "\n",
    "        cur_layer = norm_ctm.copy()\n",
    "        cur_mask = mask.copy()\n",
    "        cur_mask = (cur_mask == val).astype(np.uint8)  # Getting only the current class as the active mask\n",
    "        cur_layer = style_img_magenta(cur_layer, segment_styles.get(i), hub_module)  # Get style of current layer\n",
    "        cur_layer = np.squeeze(cur_layer)  # Convert EagerTensor instance to a typical image dimension\n",
    "\n",
    "        for j in range(stylized_image.shape[0]):\n",
    "            for k in range(stylized_image.shape[1]):\n",
    "                if cur_mask[j][k] == 1:\n",
    "                    stylized_image[j][k] = cur_layer[j][k].copy()\n",
    "\n",
    "    return stylized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The content images available by default are: {content_images}\\n')\n",
    "print(f'The style images available by default are: {style_images}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "# Configure file names and paths\n",
    "segment_images_dir = os.path.join(cwd, 'segmentation_test_img')\n",
    "base = 'guy1'\n",
    "img_path = os.path.join(segment_images_dir, f'{base}.jpg')\n",
    "mask_path = os.path.join(segment_images_dir, f'{base}_mask.png')\n",
    "\n",
    "# Read in the input image and mask\n",
    "img = plt.imread(img_path)\n",
    "img = img.astype(int)\n",
    "mask = plt.imread(mask_path)\n",
    "mask = mask.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_styles = {0: style_images[0], 1: style_images[1]}  # Style both foreground and background\n",
    "# segment_styles = {0: style_images[1]}  # Only style foreground\n",
    "# segment_styles = {1: style_images[1]}  # Only style background\n",
    "\n",
    "for region, style_img in segment_styles.items():\n",
    "    segment_styles[region] = plt.imread(os.path.join(img_dir, 'styles', style_img))\n",
    "\n",
    "masked_stylized = masked_stylize(img, mask, segment_styles)\n",
    "show_img([img, mask, masked_stylized], titles=['Original Content Image', 'Mask', 'Stylized Image (Output - Segmentation)'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6cba64f92086cea4f7c8f7f244f42e1e8cb9624a24fb73ff9c983ad8555d3f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('multitask-bert': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
