{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version:  2.7.0\n",
      "TF-Hub version:  0.12.0\n",
      "Eager mode enabled:  True\n",
      "GPU available:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 11:01:29.740915: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import functools\n",
    "import os\n",
    "\n",
    "# from matplotlib import gridspec\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "print(\"TF Version: \", tf.__version__)\n",
    "print(\"TF-Hub version: \", hub.__version__)\n",
    "print(\"Eager mode enabled: \", tf.executing_eagerly())\n",
    "print(\"GPU available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @title Define image loading and visualization functions  { display-mode: \"form\" }\n",
    "\n",
    "# def crop_center(image):\n",
    "#   \"\"\"Returns a cropped square image.\"\"\"\n",
    "#   shape = image.shape\n",
    "#   new_shape = min(shape[1], shape[2])\n",
    "#   offset_y = max(shape[1] - shape[2], 0) // 2\n",
    "#   offset_x = max(shape[2] - shape[1], 0) // 2\n",
    "#   image = tf.image.crop_to_bounding_box(\n",
    "#       image, offset_y, offset_x, new_shape, new_shape)\n",
    "#   return image\n",
    "\n",
    "# @functools.lru_cache(maxsize=None)\n",
    "# def load_image(image_url, image_size=(256, 256), preserve_aspect_ratio=True):\n",
    "#   \"\"\"Loads and preprocesses images.\"\"\"\n",
    "#   # Cache image file locally.\n",
    "#   image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url)\n",
    "#   # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
    "#   img = tf.io.decode_image(\n",
    "#       tf.io.read_file(image_path),\n",
    "#       channels=3, dtype=tf.float32)[tf.newaxis, ...]\n",
    "#   img = crop_center(img)\n",
    "#   img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n",
    "#   return img\n",
    "\n",
    "# def show_n(images, titles=('',)):\n",
    "#   n = len(images)\n",
    "#   image_sizes = [image.shape[1] for image in images]\n",
    "#   w = (image_sizes[0] * 6) // 320\n",
    "#   plt.figure(figsize=(w  * n, w))\n",
    "#   gs = gridspec.GridSpec(1, n, width_ratios=image_sizes)\n",
    "#   for i in range(n):\n",
    "#     plt.subplot(gs[i])\n",
    "#     plt.imshow(images[i][0], aspect='equal')\n",
    "#     plt.axis('off')\n",
    "#     plt.title(titles[i] if len(titles) > i else '')\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Utility functions related to showing and saving images\n",
    "\n",
    "def show_img(images, titles=('',), figsize=(20, 8)):\n",
    "  plt.figure(figsize=figsize)\n",
    "  imgs = len(images)\n",
    "  for i, img in enumerate(images):\n",
    "    plt.subplot(1, imgs, i + 1)\n",
    "    if type(img) == tf.python.framework.ops.EagerTensor:\n",
    "      # The output image is by default an EagerTensor instance, hence we will need to squeeze the image dimensions for display\n",
    "      images[i] = np.squeeze(images[i])\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "def save_image(img, filename, savedir):\n",
    "    plt.imsave(os.path.join(savedir, filename), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Utility functions related to loading the magenta model and stylizing image using magenta model\n",
    "\n",
    "def load_magenta_model():\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # Load image stylization module.\n",
    "    hub_handle = os.path.join(cwd, 'models', 'magenta')\n",
    "    hub_module = hub.load(hub_handle)\n",
    "    return hub_module\n",
    "\n",
    "def style_img_magenta(content_image, style_image, hub_module):\n",
    "    # Convert to float32 numpy array, add batch dimension, and normalize to range [0, 1]. Example using numpy:\n",
    "    ctm = content_image.copy()\n",
    "    stm = style_image.copy()\n",
    "    ctm = ctm.astype(np.float32)[np.newaxis, ...] / 255.\n",
    "    stm = stm.astype(np.float32)[np.newaxis, ...] / 255.\n",
    "\n",
    "    # Optionally resize the images. It is recommended that the style image is about\n",
    "    # 256 pixels (this size was used when training the style transfer network).\n",
    "    # The content image can be any size.\n",
    "    stm = tf.image.resize(stm, (256, 256))\n",
    "\n",
    "    # Stylize image\n",
    "    outputs = hub_module(tf.constant(ctm), tf.constant(stm))\n",
    "    stylized_image = outputs[0]\n",
    "    return stylized_image\n",
    "hub_module = load_magenta_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content images available by default are: ['klcc.jpg', 'msia1.jpg', 'msia2.jpg', 'sanfran1.jpg', 'sanfran2.jpg', 'sanfran3.jpg']\n",
      "\n",
      "The style images available by default are: ['kandinsky.jpg', 'seated-nude.jpg', 'shipwreck.jpg', 'starry-night.jpg', 'the-scream.jpg', 'woman-with-hat-matisse.jpg']\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/4x_5htrx3y7fm7z77wcz8c_40000gn/T/ipykernel_67768/2121101140.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstylized_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'styled_output.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save stylized image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mshow_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontent_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstylized_image\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Original Content Image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Style Image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Stylized Image (Output)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/sg/4x_5htrx3y7fm7z77wcz8c_40000gn/T/ipykernel_67768/1649066935.py\u001b[0m in \u001b[0;36mshow_img\u001b[0;34m(images, titles, figsize)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0;31m# The output image is by default an EagerTensor instance, hence we will need to squeeze the image dimensions for display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'python'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main program here\n",
    "cwd = os.getcwd()\n",
    "img_dir = os.path.join(cwd, 'images')\n",
    "output_dir = os.path.join(cwd, 'output')\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(os.path.join(cwd, output_dir))\n",
    "\n",
    "# Content image to be chosen\n",
    "content_image_path = './klcc.jpg'\n",
    "content_images = os.listdir(os.path.join(img_dir, 'content'))\n",
    "content_images = sorted(content_images)\n",
    "print(f'The content images available by default are: {content_images}\\n')\n",
    "content_img = content_images[0]\n",
    "content_image_path = os.path.join(img_dir, 'content', content_img)\n",
    "content_image = plt.imread(content_image_path)\n",
    "\n",
    "# Choosing style image\n",
    "style_images = os.listdir(os.path.join(img_dir, 'styles'))\n",
    "style_images = sorted(style_images)\n",
    "print(f'The style images available by default are: {style_images}\\n')\n",
    "style_img = style_images[2]\n",
    "\n",
    "style_image_path = os.path.join(img_dir, 'styles', style_img)\n",
    "style_image = plt.imread(style_image_path)\n",
    "\n",
    "\n",
    "stylized_image = style_img_magenta(content_image=content_image, style_image=style_image, hub_module=hub_module)\n",
    "stylized_image = np.squeeze(stylized_image)  # Prepare EagerTensor image for display\n",
    "\n",
    "save_image(stylized_image, 'styled_output.jpg', output_dir)  # Save stylized image\n",
    "show_img([content_image, style_image, stylized_image], titles=['Original Content Image', 'Style Image', 'Stylized Image (Output)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
